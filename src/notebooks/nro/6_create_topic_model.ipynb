{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*.ipynb filter=strip-notebook-output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "import json \n",
    "import logging\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "from utils import create_fh_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations of json files + a place to store a log\n",
    "src = Path.cwd().parent.parent.parent.parent  / 'processing' / 'nro_declassified' / 'tokenized'\n",
    "dst = src.parent / 'topics'\n",
    "files = list(src.glob('*json'))\n",
    "logs = src.parent.parent / 'logs'\n",
    "logs.mkdir(exist_ok=True)\n",
    "logger = create_fh_logger(logs / \"topic_model.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "stopwords = ['shall', 'camera', 'corona', 'mission', 'film']\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    words = [item['word'] for item in data if item['word'] not in stopwords] # more edge cases\n",
    "    documents.append(preprocess_string((' ').join(words))) # some edge cases I still missed, letting gensim pick up the slack here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(documents)\n",
    "dictionary.filter_extremes(no_below=0.05, no_above=0.8)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.009*\"control\" + 0.006*\"frame\" + 0.006*\"us\" + 0.006*\"oper\" + 0.006*\"color\" + 0.006*\"imag\" + 0.005*\"time\" + 0.005*\"resolut\" + 0.005*\"test\" + 0.005*\"pass\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.006*\"oper\" + 0.006*\"frame\" + 0.005*\"test\" + 0.005*\"data\" + 0.005*\"resolut\" + 0.005*\"time\" + 0.005*\"control\" + 0.005*\"imag\" + 0.004*\"flight\" + 0.004*\"exposur\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.007*\"frame\" + 0.006*\"time\" + 0.005*\"vehicl\" + 0.005*\"control\" + 0.005*\"oper\" + 0.004*\"pass\" + 0.004*\"imag\" + 0.004*\"figur\" + 0.004*\"rev\" + 0.004*\"us\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.011*\"program\" + 0.007*\"test\" + 0.006*\"oper\" + 0.005*\"launch\" + 0.005*\"vehicl\" + 0.005*\"us\" + 0.005*\"satellit\" + 0.005*\"control\" + 0.005*\"recoveri\" + 0.004*\"air\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0 is a strange combination of memos, performance evaluation reports, and tech docs.\n",
    "\n",
    "Topic 1 is mostly flight data books and performance evaluation reports -> more operational in nature.\n",
    "\n",
    "Topic 2 seems to be strongly influenced by the presence of `figure`, likely figures. It contains several manuals and documents.\n",
    "\n",
    "Topic 3 is mostly a variety of memos that seem to be focused on interactions with the public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document_num, doc in enumerate(corpus):\n",
    "    doc_topics = lda_model.get_document_topics(doc)\n",
    "    # Optionally, sort the topics by their contribution to this document\n",
    "    doc_topics_sorted = sorted(doc_topics, key=lambda x: x[1], reverse=False)\n",
    "    for topic_num, prop_topic in doc_topics_sorted:\n",
    "        # Print the top topic and its contribution\n",
    "        if topic_num == 2 and prop_topic>.9:\n",
    "            print(f\"Document {document_num} Top Topics: {doc_topics}\")\n",
    "            print(f'File: {files[document_num]}')\n",
    "            print(f\"Top topic: {topic_num}, Contribution: {prop_topic:.4f}\")\n",
    "            # Print top words for this topic\n",
    "            word_contributions = lda_model.show_topic(topic_num)\n",
    "            print(f\"Top words for top topic: {word_contributions}\")\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
